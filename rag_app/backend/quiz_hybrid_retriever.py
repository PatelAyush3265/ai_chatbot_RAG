"""
Hybrid Retrieval System for Quiz Generator
Combines Cosine Similarity (semantic) and BM25 (keyword-based) scoring.
Final Score = 0.7 × CosineSimilarity + 0.3 × BM25
Works with vector database (ChromaDB) for persistent storage.
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Tuple
import re
import chromadb
from chromadb.config import Settings
import logging

logger = logging.getLogger(__name__)


class QuizHybridRetriever:
    """Hybrid retrieval combining semantic similarity and BM25 keyword matching with vector DB storage."""
    
    def __init__(self, 
                 model_name: str = 'all-MiniLM-L6-v2',
                 cosine_weight: float = 0.7,
                 bm25_weight: float = 0.3,
                 threshold: float = 0.45,
                 persist_directory: str = None):
        """
        Initialize hybrid retriever with vector database.
        
        Args:
            model_name: Sentence transformer model name
            cosine_weight: Weight for cosine similarity (default 0.7)
            bm25_weight: Weight for BM25 score (default 0.3)
            threshold: Minimum score threshold for retrieval (default 0.45)
            persist_directory: Directory for ChromaDB persistence
        """
        self.model = SentenceTransformer(model_name)
        self.cosine_weight = cosine_weight
        self.bm25_weight = bm25_weight
        self.threshold = threshold
        
        # Initialize vector database
        if persist_directory:
            logger.info(f"Initializing ChromaDB at {persist_directory}")
            self.client = chromadb.PersistentClient(
                path=persist_directory,
                settings=Settings(anonymized_telemetry=False)
            )
        else:
            logger.info("Using in-memory ChromaDB")
            self.client = chromadb.Client()
        
        # Create or get quiz collection (separate namespace)
        self.collection = self.client.get_or_create_collection(
            name="quiz_documents",
            metadata={"description": "Quiz document embeddings for RAG"}
        )
        
        # Storage for chunks and BM25 index (in-memory for keyword search)
        self.chunks = []
        self.bm25 = None
        self.tokenized_chunks = []
        
        logger.info("Quiz Hybrid Retriever initialized")
    
    def index_chunks(self, chunks: List[Dict[str, any]], embeddings: List[List[float]], session_id: str = "default"):
        """
        Index chunks for retrieval by storing embeddings in vector DB and creating BM25 index.
        Implements full RAG preprocessing pipeline:
        - Embeddings already generated by document processor
        - Store in vector database with valid namespace
        
        Args:
            chunks: List of text chunks with metadata
            embeddings: Pre-computed embeddings for chunks
            session_id: Session identifier for namespace isolation
        """
        if len(chunks) != len(embeddings):
            raise ValueError(f"Mismatch: {len(chunks)} chunks but {len(embeddings)} embeddings")
        
        self.chunks = chunks
        texts = [chunk['text'] for chunk in chunks]
        
        logger.info(f"Storing {len(chunks)} chunks in vector database (session: {session_id})...")
        
        # Store in ChromaDB with valid format
        ids = [f"{session_id}_chunk_{i}" for i in range(len(chunks))]
        metadatas = [
            {
                'chunk_id': chunk['chunk_id'],
                'start_char': chunk['start_char'],
                'end_char': chunk['end_char'],
                'session_id': session_id
            }
            for chunk in chunks
        ]
        
        try:
            self.collection.add(
                ids=ids,
                documents=texts,
                embeddings=embeddings,
                metadatas=metadatas
            )
            logger.info("✓ Embeddings stored in vector database")
        except Exception as e:
            logger.error(f"Error storing embeddings: {e}")
            raise
        
        logger.info("Creating BM25 index for keyword search...")
        # Tokenize chunks for BM25 (keyword-based scoring)
        self.tokenized_chunks = [self._tokenize(text) for text in texts]
        self.bm25 = BM25Okapi(self.tokenized_chunks)
        
        logger.info("✓ Indexing complete!")
    
    def _tokenize(self, text: str) -> List[str]:
        """
        Tokenize text for BM25.
        
        Args:
            text: Text to tokenize
            
        Returns:
            List of tokens (words)
        """
        # Convert to lowercase and split by non-alphanumeric characters
        tokens = re.findall(r'\b\w+\b', text.lower())
        return tokens
    
    def _normalize_scores(self, scores: np.ndarray) -> np.ndarray:
        """
        Normalize scores to [0, 1] range using min-max normalization.
        
        Args:
            scores: Array of scores
            
        Returns:
            Normalized scores
        """
        scores = np.array(scores)
        if len(scores) == 0:
            return scores
        
        min_score = np.min(scores)
        max_score = np.max(scores)
        
        # Avoid division by zero
        if max_score == min_score:
            return np.ones_like(scores)
        
        return (scores - min_score) / (max_score - min_score)
    
    def retrieve(self, query: str, top_k: int = 10, session_id: str = "default") -> List[Dict[str, any]]:
        """
        Retrieve relevant chunks using hybrid scoring (0.7 × Cosine + 0.3 × BM25).
        
        Args:
            query: Search query
            top_k: Number of top chunks to retrieve
            session_id: Session identifier to filter results
            
        Returns:
            List of retrieved chunks with scores and metadata
        """
        if not self.chunks:
            raise ValueError("No chunks indexed. Call index_chunks() first.")
        
        # Get query embedding for cosine similarity (semantic search)
        query_embedding = self.model.encode([query])[0]
        
        # Retrieve from vector database using semantic similarity
        logger.info(f"Querying vector database for session: {session_id}")
        db_results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=min(top_k * 2, len(self.chunks)),  # Get more candidates for hybrid scoring
            where={"session_id": session_id}
        )
        
        # Extract embeddings and calculate cosine scores
        if not db_results['documents'][0]:
            logger.warning("No results from vector database")
            return []
        
        # Get stored embeddings from DB
        stored_embeddings = db_results['embeddings'][0] if db_results.get('embeddings') else None
        
        # Calculate cosine similarity scores
        if stored_embeddings:
            cosine_scores = cosine_similarity(
                [query_embedding], 
                stored_embeddings
            )[0]
        else:
            # Fallback: calculate from texts
            logger.warning("Embeddings not in query results, recalculating...")
            texts = db_results['documents'][0]
            temp_embeddings = self.model.encode(texts, show_progress_bar=False)
            cosine_scores = cosine_similarity(
                [query_embedding],
                temp_embeddings
            )[0]
        
        # Calculate BM25 scores (keyword-based scoring)
        query_tokens = self._tokenize(query)
        bm25_scores = self.bm25.get_scores(query_tokens)
        
        # Normalize both scores to [0, 1]
        cosine_norm = self._normalize_scores(cosine_scores)
        bm25_norm = self._normalize_scores(bm25_scores[:len(cosine_scores)])  # Match lengths
        
        # Combine scores using configured weights: 0.7 × Cosine + 0.3 × BM25
        hybrid_scores = (
            self.cosine_weight * cosine_norm + 
            self.bm25_weight * bm25_norm
        )
        
        # Get top-k indices
        top_indices = np.argsort(hybrid_scores)[::-1][:top_k]
        
        # Filter by threshold and create results
        results = []
        for idx in top_indices:
            score = hybrid_scores[idx]
            if score >= self.threshold:
                # Get original chunk
                chunk_idx = db_results['metadatas'][0][idx]['chunk_id']
                chunk = self.chunks[chunk_idx].copy()
                chunk['score'] = float(score)
                chunk['cosine_score'] = float(cosine_scores[idx])
                chunk['bm25_score'] = float(bm25_scores[chunk_idx]) if chunk_idx < len(bm25_scores) else 0.0
                results.append(chunk)
        
        logger.info(f"Retrieved {len(results)} chunks with hybrid scoring")
        return results
    
    def get_retrieval_stats(self, retrieved_chunks: List[Dict[str, any]]) -> Dict[str, any]:
        """
        Get statistics about retrieved chunks.
        
        Args:
            retrieved_chunks: Chunks from retrieve()
            
        Returns:
            Dictionary with statistics
        """
        if not retrieved_chunks:
            return {
                'num_retrieved': 0,
                'avg_score': 0,
                'max_score': 0,
                'min_score': 0
            }
        
        scores = [chunk['score'] for chunk in retrieved_chunks]
        
        return {
            'num_retrieved': len(retrieved_chunks),
            'avg_score': float(np.mean(scores)),
            'max_score': float(np.max(scores)),
            'min_score': float(np.min(scores))
        }
